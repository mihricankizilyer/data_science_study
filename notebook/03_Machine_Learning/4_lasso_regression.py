# -*- coding: utf-8 -*-
"""Lasso Regression

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gJiOuvfJtzGM8G0u_pDVUfM6yXy2aR78

Amaç hata kareler toplamını minimize eden katsayıları bu katsayılara bir ceza uygulayarak bulmaktır.

- Ridge reg ilgili ilgisiz tüm değişkenleri modelde bırakma dezavantajını gidermek için önerilmiştir.

- Lassado katsayılar sıfıra yaklaştırılır.

- Fakat L1 normu lamda yeteri kadar büyük olduğunda bazı katsayıları sıfır yapar. Böylece değişken seçimi yapmış olur.

- Lambdanın doğru seçilmesi çok önemlidir, burada da Cv kullanılır.

- Ridge ve Lasso yöntemleri birbirinden üstün değilidir.

- Lamdanın sıfır olduğu yer EKK'dır. HKT'yi minimum yapan lamdayı arıyoruz

- Lamda için belirli değerleri içeren bir küme seçilir ve her birisi için cross validation test hatası hesaplanır.

- En küçük cross validationı veren lamda ayar parametresi olarak seçilir.

- Son olarak seçilen bu lambda ile model yeniden tüm gözlemlere fit edilir.

## **Model**
"""

import numpy as np
import pandas as pd
from sklearn.linear_model import Ridge, Lasso
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn import model_selection
import matplotlib.pyplot as plt
from sklearn.linear_model import RidgeCV
from sklearn.linear_model import LassoCV

#Veri Seti

df = pd.read_csv("/content/Hitters.csv")

df = df.dropna()
#İçerisindeki eksik değerler atılır

dms = pd.get_dummies(df[['League','Division','NewLeague']])
#Veri seti içerisindeki kategorik değişkenleri dummy değişkenine çevirilir.
#Kategorik değişkenlerin sunduğu bilgiyi daha iyi alabilmek adına
#One hot encoding yapılmış oldu.

y= df["Salary"]
#Bağımlı değişken

X_ = df.drop(['Salary','League','Division','NewLeague'], axis = 1).astype('float64')

X = pd.concat([X_, dms[['League_N','Division_W','NewLeague_N']]], axis=1)

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25, random_state = 42)

df.head()

df.shape

lasso_model = Lasso().fit(X_train, y_train)

lasso_model

lasso_model.intercept_

lasso_model.coef_

#farklı lambda değerlerine karşılık katsayılar

lasso = Lasso()
coefs = []
alphas = np.random.randint(0,1000,10)
for a in alphas:
  lasso.set_params(alpha = a)
  lasso.fit(X_train, y_train)
  coefs.append(lasso.coef_)

ax = plt.gca()
ax.plot(alphas, coefs)
ax.set_xscale("log")

# Yeterki kadar lambda değerleri gelirse bu değerleri sıfıra yaklaştırır.

"""## **Tahmin**"""

lasso_model

lasso_model.predict(X_train)[0:5]

y_pred = lasso_model.predict(X_train)

np.sqrt(mean_squared_error(y_test, y_pred))
#İlkel test hatası
#Optimize edilmemiş modelin test hatası

r2_score(y_test, y_pred)
#Bağımsız değişkenlerce bağımlı değişkendeki değişikliğin açıklanma yüzdesidir.

"""## **Model Tuning**"""

lass_cv_model = LassoCV(cv = 10, max_iter = 1000).fit(X_train, y_train)

lasso_cv_model.alpha_

lasso_tuned = Lasso().set_params(alpha = lasso_cv_model.alpha_).fit(X_train, y_train)

y_pred = lasso_tuned.predict(X_test)

np.sqrt(mean_squared_error(y_test, y_pred))
#bağımsız değişken değerleri yerine girildiğinde bağımlı değişken değerleri alacak.

pd.Series(lasso_tuned.coef_, index=X_train.columns)

"""# **ElasticNet Regresyon**

Amaç hata kareler toplamını minimize eden katsayıları bu katsayılara bir ceza uygulayarak bulmaktır.
"""

#ElasticNet L1 ve L2 yaklaşımlarını birleştirir.

"""# **Model**"""

import numpy as np
import pandas as pd
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn import model_selection
import matplotlib.pyplot as plt
from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV

#Veri Seti

df = pd.read_csv("/content/Hitters.csv")

df = df.dropna()
#İçerisindeki eksik değerler atılır

dms = pd.get_dummies(df[['League','Division','NewLeague']])
#Veri seti içerisindeki kategorik değişkenleri dummy değişkenine çevirilir.
#Kategorik değişkenlerin sunduğu bilgiyi daha iyi alabilmek adına
#One hot encoding yapılmış oldu.

y= df["Salary"]
#Bağımlı değişken

X_ = df.drop(['Salary','League','Division','NewLeague'], axis = 1).astype('float64')

X = pd.concat([X_, dms[['League_N','Division_W','NewLeague_N']]], axis=1)

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25, random_state = 42)

enet_model = ElasticNet().fit(X_train, y_train)

enet_model.coef_

enet_model.intercept_

#Tahmin

enet_model.predict(X_train)[0:10]

enet_model.predict(X_test)[0:10]

y_pred = enet_model.predict(X_test)

np.sqrt(mean_squared_error(y_test, y_pred))

r2_score(y_test, y_pred)

"""## **Model Tuning**"""

enet_cv_model = ElasticNetCV(cv = 10).fit(X_train, y_train)

enet_cv_model.alpha_

enet_cv_model.intercept_

enet_cv_model.coef_

#Rich tarzı cezalandırma lasso tarzı değişken seçilimi

#final modeli

enet_tuned=ElasticNet(alpha = enet_cv_model.alpha).fit(X_train, y_train)

y_pred = enet_tuned.predict(X_test)

np.sqrt(mean_squared_error(y_test, y_pred))

